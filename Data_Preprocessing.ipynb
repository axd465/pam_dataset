{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Pre-Start Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSu55NMAg340"
   },
   "source": [
    "## Import Statements (Always Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "phIROnd7F_JQ",
    "outputId": "7c4d194e-0170-49ee-9932-05c46eacbe94"
   },
   "outputs": [],
   "source": [
    "# customary imports:\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcyGPWatiZRx"
   },
   "source": [
    "## *If Running In Colab* - Sets Current Working Dir to Your Google Drive Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JzTqxwZUg346",
    "outputId": "85eee941-d05e-48ce-c77e-4882da6a76a5"
   },
   "outputs": [],
   "source": [
    "your_drive_dir = 'YourGoogleDriveDirectoryPath'\n",
    "os.chdir('/content/drive/' + your_drive_dir)\n",
    "print(\"Current Working Directory is : \" + os.getcwd())\n",
    "import preprocess_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data Preprocessing - Do not run if data folders already established"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCtLTkWNg348"
   },
   "source": [
    "## Function to Convert .mat folder into Another File Format and Reject Unwanted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMrHcsnKg348",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from utils.data_preprocessing_utils import convert_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Convertion / Automated Rejection...\n",
      "\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/190309_brain  6_Image3.mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/190309_brain  6_Image4.mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/20190508_thinnedskull_Epi_by 2    3_Image1.mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_1 (10).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_1 (12).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_1 (38).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_2 (10).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_2 (36).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_3 (15).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_3 (17).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_3 (23).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_3 (24).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_3 (28).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_3 (29).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_3 (30).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_4 (10).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_4 (11).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_4 (12).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_4 (13).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_4 (14).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_4 (18).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_4 (19).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_4 (20).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_4 (23).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_4 (24).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_4 (25).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_5 (10).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_5 (11).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_5 (12).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_5 (17).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_5 (18).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_5 (21).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_5 (22).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_5 (8).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_5 (9).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_6 (11).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_6 (12).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_6 (13).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_6 (16).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_6 (5).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_6 (6).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_6 (7).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_6 (8).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_6 (9).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_7 (12).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_7 (13).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_7 (16).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_7 (5).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_7 (6).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_7 (7).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_7 (8).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_7 (9).mat\n",
      "Noisy Image: Datapoint Rejected -> raw_data/reslt_OR_8 (12).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_8 (15).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_8 (5).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_8 (6).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_8 (7).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_8 (8).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_8 (9).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_9 (10).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_9 (11).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_9 (12).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_9 (8).mat\n",
      "Min Size Not Met: Datapoint Rejected -> raw_data/reslt_OR_9 (9).mat\n",
      "\n",
      "Ending Data Convertion / Automated Rejection\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This function rejects data under specified size requirement and \n",
    "data that is noisy / has little valuable info (uses mean and std).\n",
    "This function can also perform contrast enhancement.\n",
    "'''\n",
    "raw_directory = 'raw_data'\n",
    "MIN_SHAPE = (128,128)\n",
    "ENDPOINT_FOLDER_NAME = 'converted_data'\n",
    "print('Starting Data Convertion / Automated Rejection...\\n')\n",
    "converted_dir = convert_MAP(raw_directory, ENDPOINT_FOLDER_NAME, MIN_SHAPE,\n",
    "                            file_format = '.tif', search_keys = ['map_532', 'map_all', 'DepMap_532', 'DepMap_all'],\n",
    "                            remove_noisy = True)\n",
    "print('\\nEnding Data Convertion / Automated Rejection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Data Rejection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initial data cleaning, we manually went through the images  \n",
    "and removed any that did not have clear vascular structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements:\n",
    "from utils.data_preprocessing_utils import transfer_files_except"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_REMOVAL_LIST = ['reslt_OR_1 (35)_index0', 'reslt_OR_1 (36)_index0', 'reslt_OR_1 (37)_index0', 'reslt_OR_2 (8)_index0', \n",
    "                       'reslt_OR_2 (25)_index0', 'reslt_OR_2 (29)_index0', 'reslt_OR_2 (30)_index0', 'reslt_OR_2 (31)_index0',\n",
    "                       'reslt_OR_2 (34)_index0', 'reslt_OR_2 (35)_index0', 'reslt_OR_2 (38)_index0', 'reslt_OR_2 (40)_index0', \n",
    "                       'reslt_OR_3 (25)_index0', 'reslt_OR_3 (26)_index0', 'reslt_OR_3 (31)_index0', 'reslt_OR_3 (32)_index0', \n",
    "                       'reslt_OR_3 (33)_index0', 'reslt_OR_4 (21)_index0', 'reslt_OR_4 (26)_index0', 'reslt_OR_4 (27)_index0',\n",
    "                       'reslt_OR_4 (28)_index0', 'reslt_OR_5 (19)_index0', 'reslt_OR_5 (20)_index0', 'reslt_OR_5 (23)_index0', \n",
    "                       'reslt_OR_5 (24)_index0', 'reslt_OR_5 (25)_index0', 'reslt_OR_6 (14)_index0', 'reslt_OR_6 (15)_index0', \n",
    "                       'reslt_OR_6 (18)_index0', 'reslt_OR_6 (19)_index0', 'reslt_OR_6 (20)_index0', 'reslt_OR_7 (11)_index0', \n",
    "                       'reslt_OR_7 (14)_index0', 'reslt_OR_7 (15)_index0', 'reslt_OR_7 (17)_index0', 'reslt_OR_7 (18)_index0', \n",
    "                       'reslt_OR_7 (19)_index0', 'reslt_OR_8 (13)_index0', 'reslt_OR_8 (14)_index0', 'reslt_OR_8 (16)_index0', \n",
    "                       'reslt_OR_8 (17)_index0', 'reslt_OR_8 (18)_index0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Manual Rejection...\n",
      "Ending Manual Rejection\n"
     ]
    }
   ],
   "source": [
    "file_format = '.png'\n",
    "MANUAL_REMOVAL_LIST  = [file+file_format for file in MANUAL_REMOVAL_LIST]\n",
    "input_dir = 'converted_data'\n",
    "output_dir = 'refined_data'\n",
    "print('Starting Manual Rejection...')\n",
    "transfer_files_except(input_dir, output_dir, exception_list = MANUAL_REMOVAL_LIST)\n",
    "print('Ending Manual Rejection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8A0FOljWg35A"
   },
   "source": [
    "## Function to Process Data by Denoising and Increasing Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements:\n",
    "from utils.data_preprocessing_utils import data_clean_func\n",
    "from utils.data_preprocessing_utils import data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvOVi2Xkg35D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Cleaning...\n",
      "Ending Data Cleaning\n"
     ]
    }
   ],
   "source": [
    "input_data_dir = 'refined_data'\n",
    "output_dir = 'cleaned_data'\n",
    "threshold = (10.0, 100.0) # Percentiles\n",
    "hist_eq = True \n",
    "delete_previous = True\n",
    "print('Starting Data Cleaning...')\n",
    "data_cleaning(input_dir = input_data_dir, output_dir_name = output_dir,\n",
    "              output_file_format ='.jpg', threshold = threshold, \n",
    "              hist_eq = hist_eq, delete_previous = delete_previous)\n",
    "print('Ending Data Cleaning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YecWDY3Bg35F",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Function to Seperate Folder into Subfolder of /training /validation (and /testing - optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJ3bvzrRg35G"
   },
   "outputs": [],
   "source": [
    "# Import Statements:\n",
    "from utils.data_preprocessing_utils import data_seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DBhIZspg35I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Seperation...\n",
      "Ending Data Seperation\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'cleaned_data'\n",
    "output_dir = 'data_clean'\n",
    "delete_previous = True\n",
    "file_format = '.jpeg'\n",
    "dataset_percentages = (90, 10)\n",
    "random_state = 7\n",
    "\n",
    "print('Starting Data Seperation...')\n",
    "train_dir, val_dir = data_seperation(input_dir, output_dir, dataset_percentages, \n",
    "                                     delete_previous, file_format, random_state)\n",
    "print('Ending Data Seperation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NmQuhivrg35K"
   },
   "source": [
    "### Code Block to Show How Much of Data has been Placed in various Subfolders (train/val/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9jHWHGXg35K"
   },
   "outputs": [],
   "source": [
    "print('Length of training directory = '+str(len(os.listdir(train_dir))))\n",
    "print('Length of validation directory = '+str(len(os.listdir(val_dir))))\n",
    "try:\n",
    "    print('Length of test directory = '+str(len(os.listdir(test_dir))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2GmsjLvg35M",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fo4CI9ng35V"
   },
   "source": [
    "## Padding Training Data and Adding Downsampled Image as Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements:\n",
    "from utils.standardize_dir_utils import pad_img_and_add_down_channel\n",
    "from utils.standardize_dir_utils import standardize_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'data'\n",
    "STANDARD_IMAGE_SHAPE = (128,128,1)\n",
    "downsample_axis = 'both'\n",
    "downsample_ratio = [1,5]\n",
    "file_format = '.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hh78mm5_g35Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_image_pool = 304\n"
     ]
    }
   ],
   "source": [
    "input_dir = main_dir + '/train/input'\n",
    "total_train_image_pool = standardize_dir(input_dir, downsample_axis, downsample_ratio, \n",
    "                                         STANDARD_IMAGE_SHAPE, file_format)\n",
    "print('total_train_image_pool = ' + str(total_train_image_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcU9kOvTg35d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_val_image_pool = 39\n"
     ]
    }
   ],
   "source": [
    "input_dir = main_dir + '/val/input'\n",
    "total_val_image_pool = standardize_dir(input_dir, downsample_axis, downsample_ratio, \n",
    "                                       STANDARD_IMAGE_SHAPE, file_format)\n",
    "print('total_val_image_pool = ' + str(total_val_image_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gb1xMjYNg35g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_test_image_pool = 38\n"
     ]
    }
   ],
   "source": [
    "input_dir = main_dir + '/test/input'\n",
    "total_test_image_pool = standardize_dir(input_dir, downsample_axis, downsample_ratio, \n",
    "                                        STANDARD_IMAGE_SHAPE, file_format)\n",
    "print('total_test_image_pool = ' + str(total_test_image_pool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing Image Size Using Uniform Patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.patch_utils import save_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_patches((128,128), input_dir='./data/test/input', output_dir='./data_patches/valid', file_format='.jpeg', delete_previous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BME590L-ML_Imaging-Final_Project_Code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
